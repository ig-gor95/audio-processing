# streamlit_app.py
import re
import streamlit as st
import pandas as pd
import numpy as np
from typing import List, Dict
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
from textwrap import shorten

st.set_page_config(page_title="–î–∏–∞–ª–æ–≥-–ª–µ–Ω–¥–∏–Ω–≥", layout="wide")

THEME_COL = "theme"
TEXT_COL  = "row_text"

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_data(show_spinner=False)
def load_df(upload, theme_col: str = THEME_COL) -> tuple[pd.DataFrame, int]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV/Parquet –∏ —Å—Ä–∞–∑—É –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç–æ–π —Ç–µ–º–æ–π.
    –ü—É—Å—Ç–∞—è: NaN, –ø—É—Å—Ç–∞—è/–ø—Ä–æ–±–µ–ª—å–Ω–∞—è —Å—Ç—Ä–æ–∫–∞, —Ç–µ–∫—Å—Ç–æ–≤—ã–µ 'nan'/'none'/'null'.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (df, dropped_count).
    """
    if upload is None:
        return pd.DataFrame(), 0

    name = upload.name.lower()
    if name.endswith(".csv"):
        df = pd.read_csv(upload)
    elif name.endswith(".parquet"):
        df = pd.read_parquet(upload)
    else:
        return pd.DataFrame(), 0

    dropped = 0
    if theme_col in df.columns:
        s = df[theme_col].astype(str).str.strip()
        mask = df[theme_col].notna() & s.ne("") & ~s.str.lower().isin(["nan", "none", "null"])
        dropped = int((~mask).sum())
        df = df.loc[mask].copy()

    return df, dropped


def ensure_columns(df: pd.DataFrame, cols: List[str]) -> List[str]:
    return [c for c in cols if c in df.columns]


def aggregate_by_dialog(df: pd.DataFrame, dialog_col: str, bool_cols: List[str]) -> pd.DataFrame:
    # Any-–∞–≥—Ä–µ–≥–∞—Ü–∏—è: max –ø–æ 0/1
    agg = {c: "max" for c in bool_cols}
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–Ω–µ –∞–≥—Ä–µ–≥–∏—Ä—É–µ–º –∫–ª—é—á)
    for meta in ["file_name", "duration", "status", "theme", "audio_dialog_fk_id"]:
        if meta == dialog_col:  # –Ω–∞ –≤—Å—è–∫–∏–π
            continue
        if meta in df.columns and meta not in agg:
            agg[meta] = "first"

    g = df.groupby(dialog_col, dropna=False, as_index=False).agg(agg)

    # –ï—Å–ª–∏ –Ω–µ—Ç –≥–æ—Ç–æ–≤–æ–π duration ‚Äî —Å—á–∏—Ç–∞–µ–º –ø–æ span (min(start) ‚Üí max(end))
    has_start_end = ("start" in df.columns) and ("end" in df.columns)
    if "duration" not in g.columns and has_start_end:
        dd = df.groupby(dialog_col, dropna=False).agg(start_min=("start","min"), end_max=("end","max")).reset_index()
        dd["start_min_dt"] = pd.to_datetime(dd["start_min"], errors="coerce")
        dd["end_max_dt"]   = pd.to_datetime(dd["end_max"], errors="coerce")
        if dd["start_min_dt"].notna().all() and dd["end_max_dt"].notna().all():
            dd["duration"] = (dd["end_max_dt"] - dd["start_min_dt"]).dt.total_seconds().abs()
        else:
            dd["duration"] = (pd.to_numeric(dd["end_max"], errors="coerce") - pd.to_numeric(dd["start_min"], errors="coerce")).abs()
        g = g.merge(dd[[dialog_col, "duration"]], on=dialog_col, how="left")

    # –ß—Ç–æ–±—ã –Ω–∏–≥–¥–µ –≤ UI –Ω–µ –≤—Å–ø–ª—ã–≤–∞–ª —Å—ã—Ä–æ–π theme —Å NaN:
    g = g.drop(columns=["theme"], errors="ignore")
    return g


def compute_dialog_stats(df: pd.DataFrame, dialog_col: str, speaker_col: str, operator_value: str | int) -> pd.DataFrame:
    needed = {dialog_col, speaker_col, "start", "end"}
    if not needed.issubset(df.columns):
        return pd.DataFrame()

    rows = []
    sort_cols = []
    if "audio_dialog_fk_id" in df.columns:
        sort_cols.append("audio_dialog_fk_id")
    if "row_num" in df.columns:
        sort_cols.append("row_num")
    if not sort_cols:
        sort_cols = ["start", "end"]

    for did, sub in df.sort_values(sort_cols, na_position="last").groupby(dialog_col, dropna=False):
        sub = sub.copy()
        s = pd.to_datetime(sub["start"], errors="coerce")
        e = pd.to_datetime(sub["end"], errors="coerce")
        if s.notna().all() and e.notna().all():
            seg_dur = (e - s).dt.total_seconds().clip(lower=0)
            span = float((e.max() - s.min()).total_seconds()) if len(sub) else 0.0
        else:
            s_num = pd.to_numeric(sub["start"], errors="coerce")
            e_num = pd.to_numeric(sub["end"], errors="coerce")
            seg_dur = (e_num - s_num).clip(lower=0)
            span = float((e_num.max() - s_num.min())) if len(sub) else 0.0

        total_speech = float(pd.to_numeric(seg_dur, errors="coerce").fillna(0).sum())
        total_pause = max(span - total_speech, 0.0) if span else 0.0

        op_mask = sub[speaker_col].astype(str) == str(operator_value)
        op_time = float(pd.to_numeric(seg_dur[op_mask], errors="coerce").fillna(0).sum())
        cl_time = float(pd.to_numeric(seg_dur[~op_mask], errors="coerce").fillna(0).sum())

        rows.append({
            dialog_col: did,
            "operator_time": op_time,
            "client_time": cl_time,
            "pause_time": total_pause,
            "talk_time": total_speech,
            "operator_activity_pct": (op_time / (op_time + cl_time) * 100) if (op_time + cl_time) > 0 else np.nan,
            "pause_pct_of_dialog": (total_pause / span * 100) if span > 0 else np.nan,
            "dialog_span": span,
        })
    return pd.DataFrame(rows)


def build_dialog_texts(df: pd.DataFrame, dialog_col: str, speaker_col: str, text_col: str) -> dict:
    texts = {}
    sort_cols = []
    if "audio_dialog_fk_id" in df.columns:
        sort_cols.append("audio_dialog_fk_id")
    if "row_num" in df.columns:
        sort_cols.append("row_num")
    if not sort_cols:
        sort_cols = ["start", "end"]

    def lab(x):
        if pd.isna(x): return "–°–ü–ò–ö–ï–†"
        return str(x)

    for did, sub in df.sort_values(sort_cols, na_position="last").groupby(dialog_col, dropna=False):
        lines = [f"**{lab(r[speaker_col])}:** {r[text_col]}" for _, r in sub.iterrows()]
        texts[str(did)] = "\n\n".join(lines)
    return texts


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –¢–µ–º—ã: –ø—Ä–æ–¥–∞–∂–∞ / –∂–∞–ª–æ–±–∞ / –≤–æ–ø—Ä–æ—Å (—Å—Ç—Ä–æ–≥–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _split_theme_tokens(v):
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return []
    if isinstance(v, list):
        raw = v
    else:
        s = str(v)
        for sep in [";", "|", "/", "\\"]:
            s = s.replace(sep, ",")
        raw = [x for x in (t.strip() for t in s.split(",")) if x]
    toks = []
    for t in raw:
        t = t.lower().replace("—ë", "–µ").strip(" \"'‚Äú‚Äù¬´¬ª¬∑-‚Äì‚Äî")
        t = re.sub(r"\s+", " ", t)
        toks.append(t)
    return toks


def detect_theme_sections_exact(df: pd.DataFrame, dialog_col: str, theme_col: str = THEME_COL) -> pd.DataFrame:
    """
    –ú–µ—Ç–∫–∏:
      is_purchase  -> '–ø—Ä–æ–¥–∞–∂*' –∏–ª–∏ —Ç–æ–∫–µ–Ω '–ø–æ–∫—É–ø–∫–∞' –∏–ª–∏ –∞–Ω–≥–ª. 'sale*'
      is_question  -> '–≤–æ–ø—Ä–æ—Å*'
      is_return    -> '\b–≤–æ–∑–≤—Ä–∞—Ç\w*' –∏–ª–∏ '–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—Ç–∞'
      is_complaint -> '–∂–∞–ª–æ–±\w*' –∏–ª–∏ '–ø—Ä–µ—Ç–µ–Ω–∑\w*'   (–í–ê–ñ–ù–û: –±–µ–∑ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤)
    """
    if dialog_col not in df.columns or theme_col not in df.columns:
        return pd.DataFrame()

    tmp = pd.DataFrame({dialog_col: df[dialog_col], theme_col: df[theme_col]})
    rows = []
    for did, sub in tmp.groupby(dialog_col, dropna=False):
        # —Å–æ–±—Ä–∞—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –ø–æ –¥–∏–∞–ª–æ–≥—É
        toks = []
        for v in sub[theme_col]:
            toks.extend(_split_theme_tokens(v))
        uniq = [t for t in dict.fromkeys(toks) if t]

        def any_match(patterns):
            return any(any(p.search(t) for p in patterns) for t in uniq)

        sale_patterns      = [re.compile(r"–ø—Ä–æ–¥–∞–∂–∞*", re.I)]
        question_patterns  = [re.compile(r"–≤–æ–ø—Ä–æ—Å*", re.I)]
        return_patterns    = [re.compile(r"–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—Ç–∞*", re.I)]
        complaint_patterns = [re.compile(r"–∂–∞–ª–æ–±–∞*", re.I)]

        is_purchase = any_match(sale_patterns) or ("–ø–æ–∫—É–ø–∫–∞" in uniq)
        is_question = any_match(question_patterns)
        is_return   = any_match(return_patterns)
        # –∂–∞–ª–æ–±–∞ —Ç–µ–ø–µ—Ä—å –ë–ï–ó –≤–æ–∑–≤—Ä–∞—Ç–æ–≤
        is_complaint = (any_match(complaint_patterns)) and (not is_return)

        rows.append({
            dialog_col: did,
            "is_purchase": 1 if is_purchase else 0,
            "is_complaint": 1 if is_complaint else 0,
            "is_question": 1 if is_question else 0,
            "is_return": 1 if is_return else 0,
            "themes_joined": ", ".join(uniq),
        })
    return pd.DataFrame(rows)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Sidebar & data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.sidebar.header("–î–∞–Ω–Ω—ã–µ")
if st.sidebar.button("‚ôªÔ∏è –°–±—Ä–æ—Å–∏—Ç—å –∫—ç—à"):
    st.cache_data.clear()
    st.cache_resource.clear()
    st.experimental_rerun()

upl = st.sidebar.file_uploader("CSV –∏–ª–∏ Parquet", type=["csv","parquet"])
df, dropped = load_df(upl)
if df.empty:
    st.stop()
if dropped:
    st.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ —Å—Ç—Ä–æ–∫ –±–µ–∑ —Ç–µ–º—ã: {dropped}")

# –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
dialog_col = "audio_dialog_fk_id" if "audio_dialog_fk_id" in df.columns else st.sidebar.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –¥–∏–∞–ª–æ–≥–∞", df.columns)
speaker_col = "detected_speaker_id" if "detected_speaker_id" in df.columns else st.sidebar.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å–ø–∏–∫–µ—Ä–∞", df.columns)
text_col = "row_text" if "row_text" in df.columns else st.sidebar.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Ç–µ–∫—Å—Ç–∞", df.columns)

OPERATOR_VALUE = "SALES"

# –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –±—É–ª–µ–≤—ã—Ö —Ñ–ª–∞–≥–æ–≤
candidate_bool_cols = [
    "greeting_phrase","found_name","ongoing_sale","working_hours","interjections",
    "parasite_words","abbreviations","slang","telling_name_phrases","inappropriate_phrases",
    "diminutives","stop_words","swear_words","non_professional_phrases","order_offer",
    "order_processing","order_resume","await_requests","await_requests_exit","axis_attention",
    "order_type",
    "objection_processed","evaluation_offered","script_hint_present","brand_named",
    "transfer_to_other_operator","self_pickup_address_spoken","client_contacts_taken",
    "reserve_terms","delivery_terms","end_correct","made_accent_on_availability",
    "who_finished_dialog_operator","who_finished_dialog_client","interrupts_client",
    "uncertain_speech"
]
bool_cols = ensure_columns(df, candidate_bool_cols)
for c in bool_cols:
    if pd.api.types.is_bool_dtype(df[c]):
        df[c] = df[c].astype(int)
    else:
        df[c] = df[c].apply(lambda v: bool(v) and str(v).strip().lower() not in {"0","false","–Ω–µ—Ç",""}).astype(int)

# –¢–µ–∫—Å—Ç—ã –¥–∏–∞–ª–æ–≥–æ–≤
dialog_texts = build_dialog_texts(df, dialog_col, speaker_col, text_col)

# –ê–≥—Ä–µ–≥–∞—Ç—ã –ø–æ –¥–∏–∞–ª–æ–≥–∞–º
dlg_flags = aggregate_by_dialog(df, dialog_col, bool_cols)

# –í—Ä–µ–º—è/–ø–∞—É–∑—ã
talk_stats = compute_dialog_stats(df, dialog_col, speaker_col, OPERATOR_VALUE)
if not talk_stats.empty:
    dlg_flags = dlg_flags.merge(talk_stats, on=dialog_col, how="left")

# –¢–µ–º—ã
try:
    themes_mat = detect_theme_sections_exact(df, dialog_col, theme_col=THEME_COL)
    if not themes_mat.empty:
        dlg_flags = dlg_flags.merge(themes_mat, on=dialog_col, how="left")
except Exception as _e:
    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É —Ç–µ–º: {_e}")

# –í–µ—Ä—Ö–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
n_dialogs = dlg_flags[dialog_col].nunique()
total_duration = None
if "duration" in dlg_flags.columns:
    total_duration = float(pd.to_numeric(dlg_flags["duration"], errors="coerce").fillna(0).sum())
elif "dialog_span" in dlg_flags.columns:
    total_duration = float(pd.to_numeric(dlg_flags["dialog_span"], errors="coerce").fillna(0).sum())

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç –ª–æ–≥–æ–≤ (–∫–ª–∏–∫–∞–±–µ–ª—å–Ω–æ) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_data(show_spinner=False)
def render_dialog_text(df: pd.DataFrame, dialog_col: str, speaker_col: str, text_col: str, dialog_id: str) -> str:
    """–°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –ø–æ dialog_id –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é (–±—ã—Å—Ç—Ä–æ)."""
    sub = df[df[dialog_col].astype(str) == str(dialog_id)]
    if sub.empty:
        return ""
    # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ —Ñ—Ä–∞–∑
    sort_cols = []
    if "audio_dialog_fk_id" in sub.columns: sort_cols.append("audio_dialog_fk_id")
    if "row_num" in sub.columns:            sort_cols.append("row_num")
    if not sort_cols:                        sort_cols = ["start", "end"]
    sub = sub.sort_values(sort_cols, na_position="last")

    def lab(x): return "–°–ü–ò–ö–ï–†" if pd.isna(x) else str(x)
    # plain text ‚Äî —Ä–µ–Ω–¥–µ—Ä–∏—Ç—Å—è –∑–∞–º–µ—Ç–Ω–æ –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º markdown
    lines = [f"{lab(r[speaker_col])}: {r[text_col]}" for _, r in sub.iterrows()]
    return "\n\n".join(lines)


def show_logs(filtered_df: pd.DataFrame, title: str):
    st.markdown(f"#### –õ–æ–≥–∏ ‚Äî {title}")

    # –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –≥—Ä–∏–¥–∞ (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä)
    cols_to_show = []
    for meta in ["file_name", "themes_joined", "status", "duration"]:
        if meta in filtered_df.columns:
            cols_to_show.append(meta)

    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ
    grid_df = (
        filtered_df[[dialog_col] + cols_to_show]
        .copy()
        .drop_duplicates(subset=[dialog_col])
        .rename(columns={
            "file_name": "–§–∞–π–ª",
            "themes_joined": "–¢–µ–º–∞",
            "status": "–°—Ç–∞—Ç—É—Å",
            "duration": "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Å",
            dialog_col: "dialog_id",
        })
    )

    # –æ–±–ª–µ–≥—á–µ–Ω–∏–µ DOM: —É–∫–æ—Ä–æ—Ç–∏–º ¬´–¢–µ–º–∞¬ª
    if "–¢–µ–º–∞" in grid_df.columns:
        grid_df["–¢–µ–º–∞"] = grid_df["–¢–µ–º–∞"].astype(str).apply(lambda s: shorten(s, width=120, placeholder="‚Ä¶"))

    # –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
    q = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –ª–æ–≥–∞–º", "", key=f"q_{title}")

    # AgGrid options
    gb = GridOptionsBuilder.from_dataframe(grid_df)
    gb.configure_default_column(resizable=True, sortable=True, filter=True)
    gb.configure_column("dialog_id", hide=True)
    gb.configure_selection(selection_mode="single", use_checkbox=False)
    gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=100)
    gb.configure_grid_options(
        domLayout="normal",
        rowHeight=32,
        quickFilterText=q,
        animateRows=False,                 # —á—É—Ç–∫–∞ –±—ã—Å—Ç—Ä–µ–µ
        suppressRowClickSelection=False
    )
    go = gb.build()

    grid_res = AgGrid(
        grid_df,
        gridOptions=go,
        height=520,                # —Å–∫—Ä–æ–ª–ª
        width="100%",
        theme="balham",
        fit_columns_on_grid_load=True,
        allow_unsafe_jscode=False,
        update_mode=GridUpdateMode.SELECTION_CHANGED,   # –±–µ–∑ –ø–µ—Ä–µ—Ä–µ–Ω–¥–µ—Ä–∞ –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        enable_enterprise_modules=False,
        reload_data=False,
    )

    # –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–æ—Å—Ç–∞—ë–º –≤—ã–±—Ä–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É (–≤ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏—è—Ö –±—ã–≤–∞–µ—Ç list/DF)
    sel = grid_res.get("selected_rows", [])
    # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ —Å–ø–∏—Å–∫—É —Å–ª–æ–≤–∞—Ä–µ–π
    if isinstance(sel, pd.DataFrame):
        sel = sel.to_dict(orient="records")
    elif not isinstance(sel, list):
        sel = []

    if len(sel) == 0:
        st.info("–ö–ª–∏–∫–Ω–∏—Ç–µ –ø–æ —Å—Ç—Ä–æ–∫–µ, —á—Ç–æ–±—ã –æ—Ç–∫—Ä—ã—Ç—å –¥–∏–∞–ª–æ–≥.")
        return

    did = str(sel[0].get("dialog_id"))

    st.markdown("---")
    st.markdown("##### –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç")

    # –±—ã—Å—Ç—Ä—ã–π on-demand —Ä–µ–Ω–¥–µ—Ä —Ç–µ–∫—Å—Ç–∞ (–±–µ–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –≤—Å–µ—Ö –¥–∏–∞–ª–æ–≥–æ–≤)
    txt = render_dialog_text(df, dialog_col, speaker_col, text_col, did)
    if not txt:
        st.info("–¢–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    else:
        st.text(txt)   # –±—ã—Å—Ç—Ä–µ–µ, —á–µ–º markdown

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Pages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
page = st.sidebar.radio("–°—Ç—Ä–∞–Ω–∏—Ü–∞", ["–û–±–∑–æ—Ä", "–ö—Ä–∏—Ç–µ—Ä–∏–∏"], index=0)

if page == "–û–±–∑–æ—Ä":
    st.title("üìä –û–±–∑–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤")
    c1, c2, c3 = st.columns(3)
    c1.metric("–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤", f"{n_dialogs:,}".replace(",", " "))
    if total_duration is not None:
        hours = int(total_duration // 3600)
        minutes = int((total_duration % 3600) // 60)
        c2.metric("–°—É–º–º–∞—Ä–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", f"{hours} —á {minutes} –º–∏–Ω")
    if "operator_activity_pct" in dlg_flags.columns:
        c3.metric("–°—Ä. –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞", f"{dlg_flags['operator_activity_pct'].mean():.1f}%")

    st.subheader("–†–∞–∑–¥–µ–ª—ã")
    tabs = st.tabs(["–ü—Ä–æ–¥–∞–∂–∞", "–ñ–∞–ª–æ–±–∞", "–í–æ–ø—Ä–æ—Å", "–í–æ–∑–≤—Ä–∞—Ç"])

    # –ü—Ä–æ–¥–∞–∂–∞
    with tabs[0]:
        orders_df = dlg_flags[dlg_flags.get("is_purchase", 0).fillna(0).astype(int) == 1]
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: **{len(orders_df)}**")
        show_logs(orders_df, "–ü—Ä–æ–¥–∞–∂–∞")

    # –ñ–∞–ª–æ–±–∞ (–±–µ–∑ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤)
    with tabs[1]:
        complaints_df = dlg_flags[
            (dlg_flags.get("is_complaint", 0).fillna(0).astype(int) == 1) &
            (dlg_flags.get("is_return", 0).fillna(0).astype(int) == 0)
        ]
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: **{len(complaints_df)}**")
        show_logs(complaints_df, "–ñ–∞–ª–æ–±–∞")

    # –í–æ–ø—Ä–æ—Å
    with tabs[2]:
        questions_df = dlg_flags[dlg_flags.get("is_question", 0).fillna(0).astype(int) == 1]
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: **{len(questions_df)}**")
        show_logs(questions_df, "–í–æ–ø—Ä–æ—Å")

    # –í–æ–∑–≤—Ä–∞—Ç
    with tabs[3]:
        returns_df = dlg_flags[dlg_flags.get("is_return", 0).fillna(0).astype(int) == 1]
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: **{len(returns_df)}**")
        show_logs(returns_df, "–í–æ–∑–≤—Ä–∞—Ç")

else:
    st.title("üß© –ö—Ä–∏—Ç–µ—Ä–∏–∏ –∏ –∏—Ö –¥–æ–ª—è –æ—Ç —Ç–æ—Ç–∞–ª–∞")

    criteria_map: Dict[str, List[str]] = {
        "–ü–æ–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –∏ –Ω–∞–∑–≤–∞–ª —Å–≤–æ–µ –∏–º—è": ensure_columns(dlg_flags, ["greeting_phrase","telling_name_phrases"]),
        "–û–±—Ä–∞—â–µ–Ω–∏–µ –ø–æ –∏–º–µ–Ω–∏ (–∏–ª–∏ —Å–ø—Ä–æ—Å–∏–ª –∏–º—è)": ensure_columns(dlg_flags, ["found_name"]),
        "–°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã": ensure_columns(dlg_flags, ["parasite_words"]),
        "–ú–∞—Ç—ã / –Ω–µ–ø—Ä–∏–µ–º–ª–µ–º—ã–µ —Ñ—Ä–∞–∑—ã": ensure_columns(dlg_flags, ["swear_words","inappropriate_phrases"]),
        "–°—Ç–æ–ø-—Å–ª–æ–≤–∞": ensure_columns(dlg_flags, ["stop_words"]),
        "–ü–µ—Ä–µ—Ö–æ–¥–∏—Ç –Ω–∞ –ª–∏—á–Ω–æ—Å—Ç–∏ / —Å–ª–µ–Ω–≥": ensure_columns(dlg_flags, ["slang","non_professional_phrases"]),
        "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ—Ñ–æ—Ä–º–∏—Ç—å –∑–∞–∫–∞–∑": ensure_columns(dlg_flags, ["order_offer"]),
        "–û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞–∫–∞–∑–∞": ensure_columns(dlg_flags, ["order_processing"]),
        "–ü–æ–¥–≤–µ–¥–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤ –ø–æ –∑–∞–∫–∞–∑—É": ensure_columns(dlg_flags, ["order_resume"]),
        "–†–µ–∂–∏–º –æ–∂–∏–¥–∞–Ω–∏—è": ensure_columns(dlg_flags, ["await_requests"]),
        "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –º–∞–≥–∞–∑–∏–Ω–∞": ensure_columns(dlg_flags, ["working_hours"]),
        "–°–¥–µ–ª–∞–ª –∞–∫—Ü–µ–Ω—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–∏ / –æ—Å—å –≤–Ω–∏–º–∞–Ω–∏—è": ensure_columns(dlg_flags, ["axis_attention"]),
        "–¢–∏–ø –∑–∞–∫–∞–∑–∞ / –ø–æ–¥–±–æ—Ä –ø–æ –∞–≤—Ç–æ": ensure_columns(dlg_flags, ["order_type"]),
        "–û—Ç—Ä–∞–±–æ—Ç–∞–Ω–æ –ª–∏ –≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ": ensure_columns(dlg_flags, ["objection_processed"]),
        "–ï—Å—Ç—å –ª–∏ –ø–æ–¥—Å–∫–∞–∑–∫–∞ (—Å–∫—Ä–∏–ø—Ç –¥–æ–ø –ø—Ä–æ–¥–∞–∂)": ensure_columns(dlg_flags, ["script_hint_present"]),
        "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∞ –ª–∏ –æ—Ü–µ–Ω–∫–∞": ensure_columns(dlg_flags, ["evaluation_offered"]),
        "–ö–æ–Ω—Ç–∞–∫–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞": ensure_columns(dlg_flags, ["client_contacts_taken"]),
        "–û–∑–≤—É—á–µ–Ω –∞–¥—Ä–µ—Å —Å–∞–º–æ–≤—ã–≤–æ–∑–∞": ensure_columns(dlg_flags, ["self_pickup_address_spoken"]),
        "–ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –¥—Ä—É–≥–æ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞": ensure_columns(dlg_flags, ["transfer_to_other_operator"]),
        "–°—Ä–æ–∫–∏ —Ä–µ–∑–µ—Ä–≤–∞": ensure_columns(dlg_flags, ["reserve_terms"]),
        "–°—Ä–æ–∫–∏ –¥–æ—Å—Ç–∞–≤–∫–∏": ensure_columns(dlg_flags, ["delivery_terms"]),
        "–ö—Ç–æ –∑–∞–≤–µ—Ä—à–∏–ª –¥–∏–∞–ª–æ–≥ ‚Äî –æ–ø–µ—Ä–∞—Ç–æ—Ä": ensure_columns(dlg_flags, ["who_finished_dialog_operator"]),
        "–ö—Ç–æ –∑–∞–≤–µ—Ä—à–∏–ª –¥–∏–∞–ª–æ–≥ ‚Äî –∫–ª–∏–µ–Ω—Ç": ensure_columns(dlg_flags, ["who_finished_dialog_client"]),
        "–ü–µ—Ä–µ–±–∏–≤–∞–µ—Ç –∫–ª–∏–µ–Ω—Ç–∞": ensure_columns(dlg_flags, ["interrupts_client"]),
        "–ù–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ—á–∏": ensure_columns(dlg_flags, ["uncertain_speech"]),
        "–¢–µ–º–∞: –ü—Ä–æ–¥–∞–∂–∞": ensure_columns(dlg_flags, ["is_purchase"]),
        "–¢–µ–º–∞: –ñ–∞–ª–æ–±–∞": ensure_columns(dlg_flags, ["is_complaint"]),
        "–¢–µ–º–∞: –í–æ–ø—Ä–æ—Å": ensure_columns(dlg_flags, ["is_question"]),
    }

    crit_df = pd.DataFrame({ "dialog_id": dlg_flags[dialog_col].astype(str) })
    for disp, cols in criteria_map.items():
        if not cols:
            continue
        v = np.zeros(len(dlg_flags), dtype=int)
        for c in cols:
            v = np.maximum(v, pd.to_numeric(dlg_flags[c], errors="coerce").fillna(0).astype(int).to_numpy())
        crit_df[disp] = v

    if "operator_activity_pct" in dlg_flags.columns:
        crit_df["–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞, %"] = dlg_flags["operator_activity_pct"].round(1)
    if "pause_pct_of_dialog" in dlg_flags.columns:
        crit_df["–ü–∞—É–∑—ã –≤ –¥–∏–∞–ª–æ–≥–µ, %"] = dlg_flags["pause_pct_of_dialog"].round(1)

    share_rows = []
    exclude_cols = {"dialog_id","–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞, %","–ü–∞—É–∑—ã –≤ –¥–∏–∞–ª–æ–≥–µ, %"}
    for disp in [c for c in crit_df.columns if c not in exclude_cols]:
        share = crit_df[disp].mean() * 100 if len(crit_df) else 0.0
        share_rows.append({"–ö—Ä–∏—Ç–µ—Ä–∏–π": disp, "–î–æ–ª—è –æ—Ç —Ç–æ—Ç–∞–ª–∞": round(share, 1)})
    summary = pd.DataFrame(share_rows).sort_values("–î–æ–ª—è –æ—Ç —Ç–æ—Ç–∞–ª–∞", ascending=False)
    st.dataframe(summary, use_container_width=True, hide_index=True)

    st.markdown("---")
    st.subheader("–§–∏–ª—å—Ç—Ä—ã –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º")

    OPTION_IGNORE = "–ù–µ —É—á–∏—Ç—ã–≤–∞—Ç—å"
    OPTION_T = "–¢–æ–ª—å–∫–æ –µ—Å—Ç—å"
    OPTION_F = "–¢–æ–ª—å–∫–æ –Ω–µ—Ç"

    sel_state = {}
    cols = st.columns(3)
    names = [c for c in crit_df.columns if c not in {"dialog_id","–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞, %","–ü–∞—É–∑—ã –≤ –¥–∏–∞–ª–æ–≥–µ, %"}]
    for i, name in enumerate(names):
        with cols[i % 3]:
            sel_state[name] = st.selectbox(name, options=[OPTION_IGNORE, OPTION_T, OPTION_F], index=0, key=f"sel_{name}")

    mask = pd.Series(True, index=crit_df.index)
    for name, choice in sel_state.items():
        if choice == OPTION_T:
            mask &= crit_df[name] == 1
        elif choice == OPTION_F:
            mask &= crit_df[name] == 0

    filtered_ids = set(crit_df.loc[mask, "dialog_id"].astype(str))

    st.markdown("### –õ–æ–≥–∏ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤)")
    logs = dlg_flags.copy()
    logs[dialog_col] = logs[dialog_col].astype(str)
    logs = logs[logs[dialog_col].isin(filtered_ids)]
    show_logs(logs, "–ö—Ä–∏—Ç–µ—Ä–∏–∏ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤)")  # —Ç–æ—Ç –∂–µ –∫–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
