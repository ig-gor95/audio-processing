# streamlit_app.py
import re
import streamlit as st
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode
from textwrap import shorten
from collections import Counter

st.set_page_config(page_title="–î–∏–∞–ª–æ–≥-–ª–µ–Ω–¥–∏–Ω–≥", layout="wide")

THEME_COL = "theme"
TEXT_COL  = "row_text"
DIALOG_COL_FALLBACK  = "audio_dialog_fk_id"
SPEAKER_COL_FALLBACK = "detected_speaker_id"
OPERATOR_VALUE = "SALES"   # –æ–ø–µ—Ä–∞—Ç–æ—Ä —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π

# ======== –ö–∞–Ω–¥–∏–¥–∞—Ç—ã –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ (–∫–∞–∫ –≤ CSV) ========
ALL_BOOL_CANDIDATES = [
    "greeting_phrase","found_name","ongoing_sale","working_hours","interjections",
    "parasite_words","abbreviations","slang","telling_name_phrases","inappropriate_phrases",
    "diminutives","stop_words","swear_words","non_professional_phrases","order_offer",
    "order_processing","order_resume","await_requests","await_requests_exit","axis_attention",
    "order_type","reserve_terms","delivery_terms"
]

# ¬´–ü—Ä–æ–±–ª–µ–º–Ω—ã–µ¬ª –∫—Ä–∏—Ç–µ—Ä–∏–∏ (–¥–ª—è —á–∞—Å—Ç–æ—Ç–∫–∏)
NEGATIVE_CRITERIA = [
    "parasite_words","swear_words","stop_words","slang","inappropriate_phrases",
    "non_professional_phrases","diminutives"
]

# –ü–æ—Ä—è–¥–æ–∫ –∏ —Ä—É—Å—Å–∫–∏–µ –ø–æ–¥–ø–∏—Å–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã –¥–∏–∞–ª–æ–≥–∞
CRITERIA_DISPLAY: List[Tuple[str, str]] = [
    ("greeting_phrase",          "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ"),
    ("telling_name_phrases",     "–û–±—Ä–∞—â–µ–Ω–∏–µ –ø–æ –∏–º–µ–Ω–∏"),
    ("found_name",               "–ù–∞–∑–≤–∞–ª –∏–º—è"),
    ("order_offer",              "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞–∫–∞–∑–∞"),
    ("order_processing",         "–û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞–∫–∞–∑–∞"),
    ("order_resume",             "–ü–æ–¥–≤–µ–¥–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤"),
    ("working_hours",            "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã"),
    ("reserve_terms",            "–°—Ä–æ–∫–∏ —Ä–µ–∑–µ—Ä–≤–∞"),
    ("delivery_terms",           "–°—Ä–æ–∫–∏ –¥–æ—Å—Ç–∞–≤–∫–∏"),
    ("axis_attention",           "–ê–∫—Ü–µ–Ω—Ç (–æ—Å—å)"),
    ("await_requests",           "–í—Ö–æ–¥ –≤ –æ–∂–∏–¥–∞–Ω–∏–µ"),
    ("await_requests_exit",      "–í—ã—Ö–æ–¥ –∏–∑ –æ–∂–∏–¥–∞–Ω–∏—è"),
    # –Ω–µ–≥–∞—Ç–∏–≤–Ω–∞—è –ª–µ–∫—Å–∏–∫–∞
    ("parasite_words",           "–°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã"),
    ("stop_words",               "–°—Ç–æ–ø-—Å–ª–æ–≤–∞"),
    ("slang",                    "–°–ª–µ–Ω–≥"),
    ("non_professional_phrases", "–ù–µ–ø—Ä–æ—Ñ. —Ñ—Ä–∞–∑—ã"),
    ("inappropriate_phrases",    "–ù–µ–ø—Ä–∏–µ–º–ª–µ–º—ã–µ"),
    ("swear_words",              "–ú–∞—Ç"),
    ("diminutives",              "–£–º–µ–Ω—å—à–∏—Ç–µ–ª—å–Ω—ã–µ"),
]

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@st.cache_data(show_spinner=False)
def load_df(upload, theme_col: str = THEME_COL) -> Tuple[pd.DataFrame, int]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV/Parquet –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å –ø—É—Å—Ç–æ–π —Ç–µ–º–æ–π (NaN/–ø—É—Å—Ç—ã–µ/‚Äònan‚Äô/‚Äônone‚Äô/‚Äônull‚Äô)."""
    if upload is None:
        return pd.DataFrame(), 0
    name = upload.name.lower()
    if name.endswith(".csv"):
        df = pd.read_csv(upload)
    elif name.endswith(".parquet"):
        df = pd.read_parquet(upload)
    else:
        return pd.DataFrame(), 0

    dropped = 0
    if theme_col in df.columns:
        s = df[theme_col].astype(str).str.strip()
        mask = df[theme_col].notna() & s.ne("") & ~s.str.lower().isin(["nan","none","null"])
        dropped = int((~mask).sum())
        df = df.loc[mask].copy()
    return df, dropped

def ensure_columns(df: pd.DataFrame, cols: List[str]) -> List[str]:
    return [c for c in cols if c in df.columns]

FALSE_TOKENS = {"", "0", "–Ω–µ—Ç", "false", "none", "nan", "null", "no", "off"}

def cell_to_flag(x) -> int:
    """
    –ü—Ä–∞–≤–∏–ª–æ –¥–ª—è —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤:
    - NaN/–ø—É—Å—Ç–æ/–≤ FALSE_TOKENS ‚Üí 0
    - –Ω–µ–ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Üí 1
    - —á–∏—Å–ª–æ ‚Üí 1 —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ == 1
    """
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return 0
    if isinstance(x, (int, np.integer, float, np.floating)):
        try:
            return 1 if int(float(x)) == 1 else 0
        except Exception:
            return 0
    s = str(x).strip()
    if s == "" or s.lower() in FALSE_TOKENS:
        return 0
    return 1

@st.cache_data(show_spinner=False)
def flags_line_level(df: pd.DataFrame, candidate_cols: List[str]) -> pd.DataFrame:
    """–°–æ–∑–¥–∞—ë—Ç –∫–æ–ø–∏—é df —Å 0/1-—Ñ–ª–∞–≥–∞–º–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å—Ç—Ä–æ–∫ (–æ—Ä–∏–≥–∏–Ω–∞–ª –Ω–µ —Ç—Ä–æ–≥–∞–µ–º)."""
    out = df.copy()
    for c in candidate_cols:
        if c in out.columns:
            out[c] = out[c].apply(cell_to_flag).astype(int)
        else:
            out[c] = 0
    return out

@st.cache_data(show_spinner=False)
def aggregate_by_dialog(df_flags: pd.DataFrame, dialog_col: str, bool_cols: List[str]) -> pd.DataFrame:
    """–ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –¥–∏–∞–ª–æ–≥–∞ (max –ø–æ 0/1)."""
    agg = {c: "max" for c in bool_cols}
    for meta in ["file_name", "duration", "status", "theme", "audio_dialog_fk_id"]:
        if meta == dialog_col:
            continue
        if meta in df_flags.columns and meta not in agg:
            agg[meta] = "first"
    g = df_flags.groupby(dialog_col, dropna=False, as_index=False).agg(agg)

    # duration –ø–æ span, –µ—Å–ª–∏ –Ω–µ—Ç –≥–æ—Ç–æ–≤–æ–π
    has_start_end = ("start" in df_flags.columns) and ("end" in df_flags.columns)
    if "duration" not in g.columns and has_start_end:
        dd = df_flags.groupby(dialog_col, dropna=False).agg(
            start_min=("start","min"), end_max=("end","max")
        ).reset_index()
        dd["start_min_dt"] = pd.to_datetime(dd["start_min"], errors="coerce")
        dd["end_max_dt"]   = pd.to_datetime(dd["end_max"], errors="coerce")
        if dd["start_min_dt"].notna().all() and dd["end_max_dt"].notna().all():
            dd["duration"] = (dd["end_max_dt"] - dd["start_min_dt"]).dt.total_seconds().abs()
        else:
            dd["duration"] = (pd.to_numeric(dd["end_max"], errors="coerce")
                              - pd.to_numeric(dd["start_min"], errors="coerce")).abs()
        g = g.merge(dd[[dialog_col, "duration"]], on=dialog_col, how="left")

    return g.drop(columns=["theme"], errors="ignore")

@st.cache_data(show_spinner=False)
def compute_dialog_stats(df: pd.DataFrame, dialog_col: str, speaker_col: str, operator_value: str) -> pd.DataFrame:
    """–†–∞—Å—á—ë—Ç –≤—Ä–µ–º–µ–Ω–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞/–∫–ª–∏–µ–Ω—Ç–∞/–ø–∞—É–∑ –Ω–∞ –¥–∏–∞–ª–æ–≥."""
    needed = {dialog_col, speaker_col, "start", "end"}
    if not needed.issubset(df.columns):
        return pd.DataFrame()
    rows = []
    sort_cols = []
    if "audio_dialog_fk_id" in df.columns: sort_cols.append("audio_dialog_fk_id")
    if "row_num" in df.columns:            sort_cols.append("row_num")
    if not sort_cols:                       sort_cols = ["start","end"]

    for did, sub in df.sort_values(sort_cols, na_position="last").groupby(dialog_col, dropna=False):
        s = pd.to_datetime(sub["start"], errors="coerce")
        e = pd.to_datetime(sub["end"], errors="coerce")
        if s.notna().all() and e.notna().all():
            seg_dur = (e - s).dt.total_seconds().clip(lower=0)
            span = float((e.max() - s.min()).total_seconds()) if len(sub) else 0.0
        else:
            s_num = pd.to_numeric(sub["start"], errors="coerce")
            e_num = pd.to_numeric(sub["end"], errors="coerce")
            seg_dur = (e_num - s_num).clip(lower=0)
            span = float((e_num.max() - s_num.min())) if len(sub) else 0.0

        op_mask = sub[speaker_col].astype(str) == str(operator_value)
        op_time = float(pd.to_numeric(seg_dur[op_mask], errors="coerce").fillna(0).sum())
        cl_time = float(pd.to_numeric(seg_dur[~op_mask], errors="coerce").fillna(0).sum())
        total_speech = float(pd.to_numeric(seg_dur, errors="coerce").fillna(0).sum())
        total_pause = max(span - total_speech, 0.0) if span else 0.0

        rows.append({
            dialog_col: did,
            "operator_time": op_time,
            "client_time": cl_time,
            "pause_time": total_pause,
            "talk_time": total_speech,
            "operator_activity_pct": (op_time / (op_time + cl_time) * 100) if (op_time + cl_time) > 0 else np.nan,
            "pause_pct_of_dialog": (total_pause / span * 100) if span > 0 else np.nan,
            "dialog_span": span,
        })
    return pd.DataFrame(rows)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –¢–µ–º—ã: –ø—Ä–æ–¥–∞–∂–∞ / –∂–∞–ª–æ–±–∞ / –≤–æ–ø—Ä–æ—Å / –≤–æ–∑–≤—Ä–∞—Ç ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _split_theme_tokens(v):
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return []
    if isinstance(v, list):
        raw = v
    else:
        s = str(v)
        for sep in [";", "|", "/", "\\"]:
            s = s.replace(sep, ",")
        raw = [x for x in (t.strip() for t in s.split(",")) if x]
    toks = []
    for t in raw:
        t = t.lower().replace("—ë", "–µ").strip(" \"'‚Äú‚Äù¬´¬ª¬∑-‚Äì‚Äî")
        t = re.sub(r"\s+", " ", t)
        toks.append(t)
    return toks

@st.cache_data(show_spinner=False)
def detect_theme_sections_exact(df: pd.DataFrame, dialog_col: str, theme_col: str = THEME_COL) -> pd.DataFrame:
    """–§–ª–∞–≥–∏ is_purchase / is_question / is_return / is_complaint (–±–µ–∑ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤)."""
    if dialog_col not in df.columns or theme_col not in df.columns:
        return pd.DataFrame()
    tmp = pd.DataFrame({dialog_col: df[dialog_col], theme_col: df[theme_col]})
    rows = []
    for did, sub in tmp.groupby(dialog_col, dropna=False):
        toks = []
        for v in sub[theme_col]:
            toks.extend(_split_theme_tokens(v))
        uniq = [t for t in dict.fromkeys(toks) if t]

        def any_match(patterns): return any(any(p.search(t) for p in patterns) for t in uniq)

        sale_patterns      = [re.compile(r"–ø—Ä–æ–¥–∞–∂\w*", re.I), re.compile(r"sale\w*", re.I)]
        question_patterns  = [re.compile(r"–≤–æ–ø—Ä–æ—Å\w*", re.I)]
        return_patterns    = [re.compile(r"\b–≤–æ–∑–≤—Ä–∞—Ç\w*", re.I), re.compile(r"–æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ\s+–≤–æ–∑–≤—Ä–∞—Ç–∞", re.I)]
        complaint_patterns = [re.compile(r"–∂–∞–ª–æ–±\w*", re.I), re.compile(r"–ø—Ä–µ—Ç–µ–Ω–∑\w*", re.I)]

        is_purchase  = any_match(sale_patterns) or ("–ø–æ–∫—É–ø–∫–∞" in uniq)
        is_question  = any_match(question_patterns)
        is_return    = any_match(return_patterns)
        is_complaint = (any_match(complaint_patterns)) and (not is_return)

        rows.append({
            dialog_col: did,
            "is_purchase":  int(is_purchase),
            "is_complaint": int(is_complaint),
            "is_question":  int(is_question),
            "is_return":    int(is_return),
            "themes_joined": ", ".join(uniq),
        })
    return pd.DataFrame(rows)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ß–∞—Å—Ç–æ—Ç–∫–∞ ¬´–ø–ª–æ—Ö–∏—Ö —Ñ—Ä–∞–∑¬ª –∏–∑ –∫–æ–ª–æ–Ω–æ–∫ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SPLIT_RE = re.compile(r"[;,|/\\]+")
TRIM_CHARS = " \"'‚Äú‚Äù¬´¬ª¬∑-‚Äì‚Äî"

@st.cache_data(show_spinner=False)
def bad_words_stats(
    df: pd.DataFrame,
    criteria_cols: List[str],
    topn: int = 40,
    speaker_col: str | None = None,
    speaker_value: str = "SALES",
) -> pd.DataFrame:
    """
    –ë–µ—Ä—ë–º –°–û–î–ï–†–ñ–ò–ú–û–ï –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫-–∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ (—Ç–∞–º —Ç–µ–∫—Å—Ç —Ñ—Ä–∞–∑),
    —Ñ–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞ (SALES),
    —Å—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã —Ñ—Ä–∞–∑.
    """
    use_cols = [c for c in criteria_cols if c in df.columns]
    if not use_cols:
        return pd.DataFrame(columns=["–°–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞", "–ß–∞—Å—Ç–æ—Ç–∞", "–ö—Ä–∏—Ç–µ—Ä–∏–π"])

    # —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –≤ –õ–Æ–ë–û–ô –∏–∑ –∫–æ–ª–æ–Ω–æ–∫ –µ—Å—Ç—å –Ω–µ–ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
    any_hit = np.zeros(len(df), dtype=bool)
    for c in use_cols:
        s = df[c].astype(str).str.strip()
        hit = df[c].notna() & s.ne("") & ~s.str.lower().isin(["nan", "none", "null"])
        any_hit |= hit.to_numpy()

    if speaker_col and speaker_col in df.columns and speaker_value is not None:
        any_hit &= (df[speaker_col].astype(str) == str(speaker_value)).to_numpy()

    sub = df.loc[any_hit, use_cols].copy()
    if sub.empty:
        return pd.DataFrame(columns=["–°–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞", "–ß–∞—Å—Ç–æ—Ç–∞", "–ö—Ä–∏—Ç–µ—Ä–∏–π"])

    phrase_counter = Counter()
    per_criterion_counter = Counter()
    phrase_best_criterion: dict[str, tuple[str,int]] = {}

    for _, row in sub.iterrows():
        for c in use_cols:
            val = row.get(c)
            if pd.isna(val):
                continue
            parts = [
                re.sub(r"\s+", " ", p.strip(TRIM_CHARS).lower().replace("—ë", "–µ"))
                for p in SPLIT_RE.split(str(val))
                if p and p.strip(TRIM_CHARS)
            ]
            if not parts:
                continue
            phrase_counter.update(parts)
            per_criterion_counter.update([f"{c}||{p}" for p in parts])

    # "–æ—Å–Ω–æ–≤–Ω–æ–π" –∫—Ä–∏—Ç–µ—Ä–∏–π –¥–ª—è —Ñ—Ä–∞–∑—ã ‚Äî –≥–¥–µ –æ–Ω–∞ –≤—Å—Ç—Ä–µ—á–∞–ª–∞—Å—å —á–∞—â–µ –≤—Å–µ–≥–æ
    for key, cnt in per_criterion_counter.items():
        crit, phrase = key.split("||", 1)
        best = phrase_best_criterion.get(phrase)
        if best is None or cnt > best[1]:
            phrase_best_criterion[phrase] = (crit, cnt)

    rows = []
    for phrase, freq in phrase_counter.most_common(topn):
        rows.append({
            "–°–ª–æ–≤–æ/—Ñ—Ä–∞–∑–∞": phrase,
            "–ß–∞—Å—Ç–æ—Ç–∞": freq,
            "–ö—Ä–∏—Ç–µ—Ä–∏–π": phrase_best_criterion.get(phrase, ("", 0))[0]
        })
    return pd.DataFrame(rows)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ AgGrid –ª–æ–≥–∏ ‚Üí –≤—ã–±—Ä–∞–Ω–Ω—ã–π dialog_id ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def show_logs_and_get_dialog_id(filtered_df: pd.DataFrame, dialog_col: str, title: str) -> str | None:
    st.markdown(f"#### –õ–æ–≥–∏ ‚Äî {title}")

    cols_to_show = []
    for meta in ["file_name","themes_joined","status","duration"]:
        if meta in filtered_df.columns:
            cols_to_show.append(meta)

    grid_df = (
        filtered_df[[dialog_col] + cols_to_show]
        .copy()
        .drop_duplicates(subset=[dialog_col])
        .rename(columns={
            "file_name": "–§–∞–π–ª",
            "themes_joined":"–¢–µ–º–∞",
            "status":"–°—Ç–∞—Ç—É—Å",
            "duration":"–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å, —Å",
            dialog_col: "dialog_id"
        })
    )
    if "–¢–µ–º–∞" in grid_df.columns:
        grid_df["–¢–µ–º–∞"] = grid_df["–¢–µ–º–∞"].astype(str).apply(lambda s: shorten(s, width=120, placeholder="‚Ä¶"))

    q = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –ª–æ–≥–∞–º", "", key=f"q_{title}")

    gb = GridOptionsBuilder.from_dataframe(grid_df)
    gb.configure_default_column(resizable=True, sortable=True, filter=True)
    gb.configure_column("dialog_id", hide=True)
    gb.configure_selection(selection_mode="single", use_checkbox=False)
    gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=100)
    gb.configure_grid_options(domLayout="normal", rowHeight=32, quickFilterText=q,
                              animateRows=False, suppressRowClickSelection=False)
    go = gb.build()

    grid_res = AgGrid(
        grid_df, gridOptions=go, height=520, width="100%", theme="balham",
        fit_columns_on_grid_load=True, allow_unsafe_jscode=False,
        update_mode=GridUpdateMode.SELECTION_CHANGED, enable_enterprise_modules=False, reload_data=False
    )

    sel = grid_res.get("selected_rows", [])
    if isinstance(sel, pd.DataFrame):
        sel = sel.to_dict(orient="records")
    elif not isinstance(sel, list):
        sel = []
    if not sel:
        return None
    return str(sel[0].get("dialog_id"))

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –¢–∞–±–ª–∏—Ü–∞ —Å—Ç—Ä–æ–∫ –¥–∏–∞–ª–æ–≥–∞ —Å –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏ (‚úÖ/‚ùå) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def render_dialog_criteria_table(df: pd.DataFrame, dialog_id: str, dialog_col: str, speaker_col: str, text_col: str):
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É —Å—Ç—Ä–æ–∫ –¥–∏–∞–ª–æ–≥–∞ —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏-–∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏ (‚úÖ/‚ùå), –±–µ–∑ —Å–ø–ª–æ—à–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
    sub = df[df[dialog_col].astype(str) == str(dialog_id)].copy()
    if sub.empty:
        st.info("–ù–µ—Ç —Å—Ç—Ä–æ–∫ –¥–ª—è —ç—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞.")
        return

    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Å—Ç—Ä–æ–∫ –¥–∏–∞–ª–æ–≥–∞
    sort_cols = []
    if "audio_dialog_fk_id" in sub.columns: sort_cols.append("audio_dialog_fk_id")
    if "row_num"            in sub.columns: sort_cols.append("row_num")
    if not sort_cols:                        sort_cols = ["start","end"]
    sub = sub.sort_values(sort_cols, na_position="last")

    # –±–∞–∑–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã
    base_cols = []
    for c in ["start","end"]:
        if c in sub.columns: base_cols.append(c)
    if speaker_col in sub.columns:
        base_cols.append(speaker_col)
    if text_col in sub.columns:
        base_cols.append(text_col)

    # –ª–æ–∫–∞–ª—å–Ω–æ —Å–¥–µ–ª–∞–µ–º 0/1-—Ñ–ª–∞–≥–∏ –¥–ª—è —Å—Ç—Ä–æ–∫
    local = flags_line_level(sub, [c for c, _ in CRITERIA_DISPLAY])

    # –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤
    for col, ru in CRITERIA_DISPLAY:
        if col in local.columns:
            local[ru] = local[col].apply(lambda v: "‚úÖ" if int(v) == 1 else "‚ùå")

    show_cols = base_cols + [ru for _, ru in CRITERIA_DISPLAY if _ in local.columns]
    st.dataframe(local[show_cols], use_container_width=True, hide_index=True)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Sidebar & data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
st.sidebar.header("–î–∞–Ω–Ω—ã–µ")
if st.sidebar.button("‚ôªÔ∏è –°–±—Ä–æ—Å–∏—Ç—å –∫—ç—à"):
    st.cache_data.clear()
    st.cache_resource.clear()
    st.rerun()

upl = st.sidebar.file_uploader("CSV –∏–ª–∏ Parquet", type=["csv","parquet"])
df, dropped = load_df(upl)
if df.empty:
    st.stop()
if dropped:
    st.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ —Å—Ç—Ä–æ–∫ –±–µ–∑ —Ç–µ–º—ã: {dropped}")

# –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
dialog_col  = DIALOG_COL_FALLBACK  if DIALOG_COL_FALLBACK  in df.columns else st.sidebar.selectbox("–ö–æ–ª–æ–Ω–∫–∞ –¥–∏–∞–ª–æ–≥–∞", df.columns)
speaker_col = SPEAKER_COL_FALLBACK if SPEAKER_COL_FALLBACK in df.columns else st.sidebar.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Å–ø–∏–∫–µ—Ä–∞", df.columns)
text_col    = TEXT_COL             if TEXT_COL             in df.columns else st.sidebar.selectbox("–ö–æ–ª–æ–Ω–∫–∞ —Ç–µ–∫—Å—Ç–∞", df.columns)

# —Å–æ–∑–¥–∞—ë–º df_flags –¥–ª—è –∞–≥—Ä–µ–≥–∞—Ç–æ–≤ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π df —Å —Ç–µ–∫—Å—Ç–æ–º –ù–ï –º–µ–Ω—è–µ–º)
df_flags = flags_line_level(df, ALL_BOOL_CANDIDATES)

# –ê–≥—Ä–µ–≥–∞—Ç—ã –¥–∏–∞–ª–æ–≥–æ–≤ + —Å—Ç–∞—Ç—ã + —Ç–µ–º—ã
dlg_flags = aggregate_by_dialog(df_flags, dialog_col, ensure_columns(df_flags, ALL_BOOL_CANDIDATES))
talk_stats = compute_dialog_stats(df, dialog_col, speaker_col, OPERATOR_VALUE)
if not talk_stats.empty:
    dlg_flags = dlg_flags.merge(talk_stats, on=dialog_col, how="left")
try:
    themes_mat = detect_theme_sections_exact(df, dialog_col, theme_col=THEME_COL)
    if not themes_mat.empty:
        dlg_flags = dlg_flags.merge(themes_mat, on=dialog_col, how="left")
except Exception as _e:
    st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É —Ç–µ–º: {_e}")

# –í–µ—Ä—Ö–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
n_dialogs = dlg_flags[dialog_col].nunique()
total_duration = None
if "duration" in dlg_flags.columns:
    total_duration = float(pd.to_numeric(dlg_flags["duration"], errors="coerce").fillna(0).sum())
elif "dialog_span" in dlg_flags.columns:
    total_duration = float(pd.to_numeric(dlg_flags["dialog_span"], errors="coerce").fillna(0).sum())

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Pages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
page = st.sidebar.radio("–°—Ç—Ä–∞–Ω–∏—Ü–∞", ["–û–±–∑–æ—Ä", "–ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤"], index=0)

if page == "–û–±–∑–æ—Ä":
    st.title("üìä –û–±–∑–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤")
    c1, c2, c3 = st.columns(3)
    c1.metric("–í—Å–µ–≥–æ –¥–∏–∞–ª–æ–≥–æ–≤", f"{n_dialogs:,}".replace(",", " "))
    if total_duration is not None:
        hours = int(total_duration // 3600)
        minutes = int((total_duration % 3600) // 60)
        c2.metric("–°—É–º–º–∞—Ä–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", f"{hours} —á {minutes} –º–∏–Ω")
    if "operator_activity_pct" in dlg_flags.columns:
        c3.metric("–°—Ä. –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞", f"{dlg_flags['operator_activity_pct'].mean():.1f}%")

    st.subheader("–†–∞–∑–¥–µ–ª—ã")
    tabs = st.tabs(["–ü—Ä–æ–¥–∞–∂–∞", "–ñ–∞–ª–æ–±–∞", "–í–æ–ø—Ä–æ—Å", "–í–æ–∑–≤—Ä–∞—Ç"])

    # –ü—Ä–æ–¥–∞–∂–∞
    with tabs[0]:
        orders_df = dlg_flags[dlg_flags.get("is_purchase", 0).fillna(0).astype(int) == 1]
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: **{len(orders_df)}**")
        did = show_logs_and_get_dialog_id(orders_df, dialog_col, "–ü—Ä–æ–¥–∞–∂–∞")
        if did:
            st.markdown("---")
            st.markdown("##### –î–∏–∞–ª–æ–≥ ‚Äî —Å—Ç—Ä–æ–∫–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏")
            render_dialog_criteria_table(df, did, dialog_col, speaker_col, text_col)

    # –ñ–∞–ª–æ–±–∞ (–±–µ–∑ –≤–æ–∑–≤—Ä–∞—Ç–æ–≤)
    with tabs[1]:
        complaints_df = dlg_flags[
            (dlg_flags.get("is_complaint", 0).fillna(0).astype(int) == 1) &
            (dlg_flags.get("is_return", 0).fillna(0).astype(int) == 0)
        ]
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: **{len(complaints_df)}**")
        did = show_logs_and_get_dialog_id(complaints_df, dialog_col, "–ñ–∞–ª–æ–±–∞")
        if did:
            st.markdown("---")
            st.markdown("##### –î–∏–∞–ª–æ–≥ ‚Äî —Å—Ç—Ä–æ–∫–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏")
            render_dialog_criteria_table(df, did, dialog_col, speaker_col, text_col)

    # –í–æ–ø—Ä–æ—Å
    with tabs[2]:
        questions_df = dlg_flags[dlg_flags.get("is_question", 0).fillna(0).astype(int) == 1]
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: **{len(questions_df)}**")
        did = show_logs_and_get_dialog_id(questions_df, dialog_col, "–í–æ–ø—Ä–æ—Å")
        if did:
            st.markdown("---")
            st.markdown("##### –î–∏–∞–ª–æ–≥ ‚Äî —Å—Ç—Ä–æ–∫–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏")
            render_dialog_criteria_table(df, did, dialog_col, speaker_col, text_col)

    # –í–æ–∑–≤—Ä–∞—Ç
    with tabs[3]:
        returns_df = dlg_flags[dlg_flags.get("is_return", 0).fillna(0).astype(int) == 1]
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: **{len(returns_df)}**")
        did = show_logs_and_get_dialog_id(returns_df, dialog_col, "–í–æ–∑–≤—Ä–∞—Ç")
        if did:
            st.markdown("---")
            st.markdown("##### –î–∏–∞–ª–æ–≥ ‚Äî —Å—Ç—Ä–æ–∫–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏")
            render_dialog_criteria_table(df, did, dialog_col, speaker_col, text_col)

else:
    st.title("üß™ –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤")

    # 1) –ß–∞—Å—Ç–æ—Ç–∫–∞ ¬´–ø–ª–æ—Ö–∏—Ö —Ñ—Ä–∞–∑¬ª (–ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö, —Ç–æ–ª—å–∫–æ SALES)
    st.subheader("–ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–µ–∫—Å–∏–∫–∏")
    available_neg = [c for c in NEGATIVE_CRITERIA if c in df.columns]

    # –∫–∞–∫–∞—è –∫–æ–ª–æ–Ω–∫–∞ –ø—Ä–æ —Å–ø–∏–∫–µ—Ä–∞
    speaker_col_for_stats = (
        "speaker_id" if "speaker_id" in df.columns
        else ("detected_speaker_id" if "detected_speaker_id" in df.columns else None)
    )

    if not available_neg:
        st.info("–í –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –∫–æ–ª–æ–Ω–æ–∫ —Å ¬´–ø—Ä–æ–±–ª–µ–º–Ω–æ–π¬ª –ª–µ–∫—Å–∏–∫–æ–π.")
    else:
        cols1, cols2, cols3 = st.columns(3)
        chosen = []
        for i, c in enumerate(available_neg):
            with [cols1, cols2, cols3][i % 3]:
                if st.checkbox(c, value=False, key=f"neg_{c}"):
                    chosen.append(c)

        if chosen:
            bw = bad_words_stats(
                df,
                criteria_cols=chosen,   # –∏—Å–ø–æ–ª—å–∑—É–µ–º –°–û–î–ï–†–ñ–ò–ú–û–ï —ç—Ç–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
                topn=40,
                speaker_col=speaker_col_for_stats,
                speaker_value="SALES",  # —Å—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è SALES
            )
            st.markdown("#### –¢–æ–ø-—Ñ—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º (—Ç–æ–ª—å–∫–æ SALES)")
            st.dataframe(bw, use_container_width=True, hide_index=True)
        else:
            st.info("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –∫—Ä–∏—Ç–µ—Ä–∏–π –≤—ã—à–µ.")

    st.markdown("---")

    # 2) –î–æ–ª–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –∫—Ä–∏—Ç–µ—Ä–∏—é (–ø–æ –¥–∏–∞–ª–æ–≥–∞–º) ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º dlg_flags
    st.subheader("–î–æ–ª—è –¥–∏–∞–ª–æ–≥–æ–≤ —Å –ø—Ä–∏–∑–Ω–∞–∫–æ–º (–ø–æ –∫–∞–∂–¥–æ–º—É –∫—Ä–∏—Ç–µ—Ä–∏—é)")
    crit_map: Dict[str, List[str]] = {
        "–ü–æ–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –∏ –Ω–∞–∑–≤–∞–ª –∏–º—è": ensure_columns(dlg_flags, ["greeting_phrase","telling_name_phrases"]),
        "–û–±—Ä–∞—â–µ–Ω–∏–µ/–ø–æ–∏—Å–∫ –∏–º–µ–Ω–∏":        ensure_columns(dlg_flags, ["found_name"]),
        "–°–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã":               ensure_columns(dlg_flags, ["parasite_words"]),
        "–ú–∞—Ç—ã/–Ω–µ–ø—Ä–∏–µ–º–ª–µ–º—ã–µ":            ensure_columns(dlg_flags, ["swear_words","inappropriate_phrases"]),
        "–°—Ç–æ–ø-—Å–ª–æ–≤–∞":                   ensure_columns(dlg_flags, ["stop_words"]),
        "–õ–∏—á–Ω–æ—Å—Ç–∏/—Å–ª–µ–Ω–≥":               ensure_columns(dlg_flags, ["slang","non_professional_phrases"]),
        "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞–∫–∞–∑–∞":           ensure_columns(dlg_flags, ["order_offer"]),
        "–û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –∑–∞–∫–∞–∑–∞":            ensure_columns(dlg_flags, ["order_processing"]),
        "–†–µ–∑—é–º–µ –∑–∞–∫–∞–∑–∞":                ensure_columns(dlg_flags, ["order_resume"]),
        "–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã":                 ensure_columns(dlg_flags, ["working_hours"]),
        "–í—Ö–æ–¥ –≤ –æ–∂–∏–¥–∞–Ω–∏–µ":              ensure_columns(dlg_flags, ["await_requests"]),
        "–í—ã—Ö–æ–¥ –∏–∑ –æ–∂–∏–¥–∞–Ω–∏—è":            ensure_columns(dlg_flags, ["await_requests_exit"]),
        "–¢–∏–ø –∑–∞–∫–∞–∑–∞/–ø–æ–¥–±–æ—Ä":            ensure_columns(dlg_flags, ["order_type"]),
        "–°—Ä–æ–∫–∏ —Ä–µ–∑–µ—Ä–≤–∞":                ensure_columns(dlg_flags, ["reserve_terms"]),
        "–°—Ä–æ–∫–∏ –¥–æ—Å—Ç–∞–≤–∫–∏":               ensure_columns(dlg_flags, ["delivery_terms"]),
        "–¢–µ–º–∞: –ü—Ä–æ–¥–∞–∂–∞":                ensure_columns(dlg_flags, ["is_purchase"]),
        "–¢–µ–º–∞: –ñ–∞–ª–æ–±–∞":                 ensure_columns(dlg_flags, ["is_complaint"]),
        "–¢–µ–º–∞: –í–æ–ø—Ä–æ—Å":                 ensure_columns(dlg_flags, ["is_question"]),
        "–¢–µ–º–∞: –í–æ–∑–≤—Ä–∞—Ç":                ensure_columns(dlg_flags, ["is_return"]),
    }

    dlg_share = dlg_flags[[dialog_col]].drop_duplicates().copy()
    for disp, cols in crit_map.items():
        if not cols:
            continue
        v = np.zeros(len(dlg_flags), dtype=int)
        for c in cols:
            v = np.maximum(v, pd.to_numeric(dlg_flags[c], errors="coerce").fillna(0).astype(int).to_numpy())
        tmp = pd.DataFrame({dialog_col: dlg_flags[dialog_col], disp: v})
        tmp = tmp.groupby(dialog_col, as_index=False)[disp].max()
        dlg_share = dlg_share.merge(tmp, on=dialog_col, how="left")

    share_rows = []
    for disp in [c for c in dlg_share.columns if c != dialog_col]:
        share = pd.to_numeric(dlg_share[disp], errors="coerce").fillna(0).mean() * 100 if len(dlg_share) else 0.0
        share_rows.append({"–ö—Ä–∏—Ç–µ—Ä–∏–π": disp, "–î–æ–ª—è –æ—Ç —Ç–æ—Ç–∞–ª–∞, %": round(float(share), 1)})
    summary = pd.DataFrame(share_rows).sort_values("–î–æ–ª—è –æ—Ç —Ç–æ—Ç–∞–ª–∞, %", ascending=False)
    st.dataframe(summary, use_container_width=True, hide_index=True)

    st.markdown("---")

    # 3) –ë—ã—Å—Ç—Ä—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º ‚Üí –ª–æ–≥–∏ ‚Üí —Ç–∞–±–ª–∏—Ü–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞
    st.subheader("–ë—ã—Å—Ç—Ä—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã –∏ –ø—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤")

    # 3.1 –§–∏–ª—å—Ç—Ä –ø–æ —Å–ø–∏–∫–µ—Ä—É (–≤–ª–∏—è–µ—Ç –∏ –Ω–∞ –æ—Ç–±–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤, –∏ –Ω–∞ —Ä–µ–Ω–¥–µ—Ä —Ç–∞–±–ª–∏—Ü—ã)
    speaker_choice = st.radio(
        "–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ä–µ–ø–ª–∏–∫–∏ —Å–ø–∏–∫–µ—Ä–∞",
        ["SALES", "CLIENT"],
        index=0,  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é SALES
        horizontal=True,
        key="quick_speaker_choice",
    )

    # 3.2 –í—ã–±–æ—Ä —É—Å–ª–æ–≤–∏–π –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º (—Ç–µ –∂–µ —Ä—É—Å—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è, —á—Ç–æ –≤ dlg_share/crit_map)
    names = [c for c in dlg_share.columns if c != dialog_col]
    cols = st.columns(3)
    sel = {}
    OPTION_IGNORE, OPTION_T, OPTION_F = "–ù–µ —É—á–∏—Ç—ã–≤–∞—Ç—å", "–¢–æ–ª—å–∫–æ –µ—Å—Ç—å", "–¢–æ–ª—å–∫–æ –Ω–µ—Ç"
    for i, name in enumerate(names):
        with cols[i % 3]:
            sel[name] = st.selectbox(name, [OPTION_IGNORE, OPTION_T, OPTION_F], key=f"cf_{name}")

    # 3.3 –û—Ç–±–æ—Ä –¥–∏–∞–ª–æ–≥–æ–≤ —Å —É—á—ë—Ç–æ–º speaker_choice –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —É—Å–ª–æ–≤–∏–π –ü–û –°–¢–†–û–ö–ê–ú
    # –ù—É–∂–Ω–∞ –º–∞–ø–∞: –†—É—Å—Å–∫–æ–µ –∏–º—è –∫—Ä–∏—Ç–µ—Ä–∏—è -> —Å–ø–∏—Å–æ–∫ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç—É –∂–µ `crit_map`, —á—Ç–æ —Ç—ã —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª –≤—ã—à–µ –¥–ª—è dlg_share.
    row_df = df_flags.copy()  # –∑–¥–µ—Å—å —Ñ–ª–∞–≥–∏ 0/1 —É–∂–µ –ø–æ—Å—á–∏—Ç–∞–Ω—ã –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å—Ç—Ä–æ–∫
    if speaker_col in row_df.columns:
        row_df = row_df[row_df[speaker_col].astype(str) == speaker_choice]

    # —Å—Ç–∞—Ä—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä ‚Äî –≤—Å–µ –¥–∏–∞–ª–æ–≥–∏, –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ —Å–ø–∏–∫–µ—Ä–∞
    candidate_ids = set(row_df[dialog_col].astype(str).unique())

    for disp_name, choice in sel.items():
        if choice == OPTION_IGNORE:
            continue

        cols_for_crit = crit_map.get(disp_name, [])
        cols_for_crit = [c for c in cols_for_crit if c in row_df.columns]
        if not cols_for_crit:
            # –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–æ–∫ –Ω–µ—Ç, —ç—Ç–æ—Ç –∫—Ä–∏—Ç–µ—Ä–∏–π –Ω–∏–∫–∞–∫ –Ω–µ –≤–ª–∏—è–µ—Ç
            continue

        # –ø–æ —ç—Ç–æ–º—É –∫—Ä–∏—Ç–µ—Ä–∏—é ¬´—Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏¬ª = max –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º –∫—Ä–∏—Ç–µ—Ä–∏—è
        per_row_hit = np.zeros(len(row_df), dtype=int)
        for c in cols_for_crit:
            per_row_hit = np.maximum(per_row_hit,
                                     pd.to_numeric(row_df[c], errors="coerce").fillna(0).astype(int).to_numpy())

        tmp = row_df[[dialog_col]].copy()
        tmp["hit"] = per_row_hit
        per_dialog_hit = tmp.groupby(dialog_col, as_index=False)["hit"].max()

        if choice == OPTION_T:
            keep_ids = set(per_dialog_hit.loc[per_dialog_hit["hit"] == 1, dialog_col].astype(str))
            candidate_ids &= keep_ids
        elif choice == OPTION_F:
            keep_ids = set(per_dialog_hit.loc[per_dialog_hit["hit"] == 0, dialog_col].astype(str))
            candidate_ids &= keep_ids

    # 3.4 –õ–æ–≥–∏ + –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∏–∞–ª–æ–≥–∞
    logs = dlg_flags.copy()
    logs[dialog_col] = logs[dialog_col].astype(str)
    logs = logs[logs[dialog_col].isin(candidate_ids)]

    did = show_logs_and_get_dialog_id(logs, dialog_col, "–ö—Ä–∏—Ç–µ—Ä–∏–∏ (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–æ–≤)")
    if did:
        st.markdown("---")
        st.markdown("##### –î–∏–∞–ª–æ–≥ ‚Äî —Å—Ç—Ä–æ–∫–∏ –∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏")
        # ‚¨áÔ∏è –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤–µ—Å—å –¥–∏–∞–ª–æ–≥ (–∏ SALES, –∏ CLIENT), –±–µ–∑ —Å–ø–∏–∫–µ—Ä-—Ñ–∏–ª—å—Ç—Ä–∞
        render_dialog_criteria_table(
            df,  # <-- –ø–æ–ª–Ω—ã–π df, –Ω–µ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ speaker_choice
            did,
            dialog_col,
            speaker_col,
            text_col
        )
